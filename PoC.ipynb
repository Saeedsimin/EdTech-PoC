{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "# !pip install pdf2image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# 1. Setup the file path\n",
    "pdf_path = 'HandwrittenGrading-ReferenceSolution.pdf'\n",
    "\n",
    "# 2. Convert PDF to a list of PIL Image objects\n",
    "# If you're on Windows, add: poppler_path=r'C:\\path\\to\\poppler-xx\\Library\\bin'\n",
    "images = convert_from_path(pdf_path)\n",
    "\n",
    "# 3. Loop through images and save them\n",
    "for i, image in enumerate(images):\n",
    "    filename = f'page_{i + 1}.jpg'\n",
    "    image.save(filename, 'JPEG')\n",
    "    print(f'Saved: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab1f9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Translated Question\": \"1. (25%) In the use of voltage dividers, we encountered a compromise: for certain reasons, we want to build the divider with resistors of the smallest possible resistance, but on the other hand, we want the resistances to be as large as possible. Explain the contradiction and the reasons for it.\", \"Student Answer\": \"1. THEVENIN'S RESISTANCE OF THE DIVIDER IS \\\\( R_1 || R_2 \\\\), WHERE \\\\( R_1 \\\\) AND \\\\( R_2 \\\\) ARE THE RESISTORS THAT MAKE IT UP. WE WANT THE THEVENIN RESISTANCE TO BE AS SMALL AS POSSIBLE TO REDUCE THE LOAD VOLTAGE DROPS, => THE SMALLER THE RESISTOR. THE DIVIDER LOADS THE CURRENT SOURCE \\\\( V_1 \\\\), WHICH IS EQUAL TO \\\\( V_1 / (R_1 + R_2) \\\\). THE SMALLER THE RESISTORS, MORE CURRENT IS USED UP, AND GREATER LOSSES ARE CREATED => THE GREATER THE RESISTOR.\"}\n",
      "{\n",
      "  \"Translated Question\": \"3. (50%) Two batteries with Thevenin voltages Ut1 and Ut2 and Thevenin internal resistances Rt1 and Rt2 are connected in parallel and connected to load Rb.\\n   a. Draw the appropriate circuit.\\n   b. Write the expression for the Thevenin resistance of the source formed by the batteries.\\n   c. Write the expression for the Thevenin voltage of the source formed by the batteries.\\n   d. Write the expression for the voltage across the load Rb.\",\n",
      "  \"Student Answer\": \"c) THEVENINOVA NAPETOST\\n\\\\[U_T = \\\\frac{R_{T2}}{R_{T1} + R_{T2}} \\\\cdot U_{T1} + \\\\frac{R_{T1}}{R_{T1} + R_{T2}} \\\\cdot U_{T2}\\\\]\\n\\nb) THEVENINOVA UPORNOST\\n\\\\[R_T = R_{T1} || R_{T2}\\\\]\\n\\nd) NAPETOST BREMENA\\n\\\\[U_B = \\\\frac{R_B}{R_B + R_T} \\\\cdot U_T\\\\]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def stage_1_ocr(image_path):\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    base64_image = encode_image(image_path)\n",
    "    prompt = f\"\"\"\"In this .jpg:\n",
    "      \n",
    "      1) Translate the question in English. \n",
    "      2) Transcribe student Answer. \n",
    "      3) If you see math, use LaTeX. \n",
    "      \n",
    "      Output JSON = {{'Translated Question:\"', Student Answer:\"\"}}\n",
    "      \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            \"detail\": \"high\"  # Critical for handwriting accuracy\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def extract_student_work(image_url):\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"OCR this student paper. If it is math, use LaTeX for symbols. Output ONLY valid JSON.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "                ],\n",
    "            }\n",
    "        ], \n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "for img in glob.glob(\"real exam/*.jpg\"):\n",
    "    print(stage_1_ocr(img))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d309d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_2_3_grade(transcription, rubric_type=\"science\"):\n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    # Define rubrics for your two samples\n",
    "    rubrics = {\n",
    "        \"science\": \"1pt: Powerhouse concept. 1pt: ATP mention. Deduct 0.5pt: 'Makes energy' (incorrect phrasing).\",\n",
    "        \"math\": \"1pt: Isolate x term. 1pt: Final answer. Deduct 1pt: Arithmetic error.\"\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a strict academic grader. \n",
    "    Rubric: {rubrics[rubric_type]}\n",
    "    Student Work: {transcription}\n",
    "\n",
    "    Follow this logic:\n",
    "    1. internal_monologue: Break down the student's logic step-by-step.\n",
    "    2. Identify specific strengths and weaknesses.\n",
    "    3. Calculate the final score.\n",
    "    \n",
    "    Output JSON: {{ \"internal_monologue\": \"\", \"score\": 0.0, \"strengths\": [], \"weaknesses\": [], \"feedback\": \"\" }}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# stage_2_3_grade()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212cfdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class RubricCriteria(BaseModel):\n",
    "    name: str  # e.g., \"Scientific Accuracy\" or \"Algebraic Logic\"\n",
    "    weight: float\n",
    "    description: str\n",
    "\n",
    "class MarkingTask(BaseModel):\n",
    "    question: str\n",
    "    model_answer: str\n",
    "    student_answer: str\n",
    "    criteria: List[RubricCriteria] # This makes it \"General\"\n",
    "\n",
    "def generate_dynamic_grade(task: MarkingTask):\n",
    "    # This prompt works for ANY subject\n",
    "    system_prompt = f\"\"\"\n",
    "    You are a professional examiner. \n",
    "    Grade the student's answer based on the following criteria:\n",
    "    {[(c.name, c.description) for c in task.criteria]}\n",
    "    \n",
    "    Reference Model Answer: {task.model_answer}\n",
    "    Student Work: {task.student_answer}\n",
    "    \"\"\"\n",
    "    client = openai(api_key=api_key)\n",
    "    client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages = \n",
    "    )\n",
    "    # Send to OpenAI...\n",
    "\n",
    "# Example usage:\n",
    "# raw_json = grade_answer(extracted_text, science_rubric)\n",
    "# validated_data = EvaluationSchema.model_validate_json(raw_json)\n",
    "# print(validated_data.score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM - BERT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
